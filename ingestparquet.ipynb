from pyspark.sql  import SparkSession
spark = SparkSession.builder.getOrCreate()
sc = spark.sparkContext

data = spark.read.format('csv').options(header='true', inferSchema='true').load('s3://msbx5420-2020/team_castle_peak/news_cleaned.csv')

data.show()
data.printSchema()

result_path = 's3://msbx5420-2020/team_castle_peak/news.parquet'

data.write.parquet(result_path)

parqDF = spark.read.parquet(result_path)

parqDF

parqDF.show()
parqDF.printSchema()
